#!/usr/bin/env python3
"""
æµ‹è¯•çˆ¬å–åŠŸèƒ½çš„ç®€å•è„šæœ¬
"""
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(__file__))

from src.crawlers.pubmed_crawler import PubMedCrawler
from src.crawlers.arxiv_crawler import ArxivCrawler

def test_pubmed_crawler():
    """æµ‹è¯•PubMedçˆ¬è™«"""
    print("æµ‹è¯•PubMedçˆ¬è™«...")
    
    config = {
        'DATA_SOURCES': {
            'pubmed': {
                'base_url': 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/',
                'api_key': None,
                'email': 'test@example.com'
            }
        },
        'CRAWL_DELAY': 1,
        'MAX_PAPERS_PER_QUERY': 5
    }
    
    crawler = PubMedCrawler(config)
    
    try:
        # æµ‹è¯•æœç´¢
        papers = crawler.search_papers("machine learning", max_results=3)
        print(f"PubMedæœç´¢ç»“æœ: {len(papers)} ç¯‡è®ºæ–‡")
        
        if papers:
            print("ç¬¬ä¸€ç¯‡è®ºæ–‡:")
            paper = papers[0]
            print(f"  æ ‡é¢˜: {paper.get('title', 'N/A')[:100]}...")
            print(f"  ä½œè€…: {', '.join(paper.get('authors', [])[:3])}")
            print(f"  æœŸåˆŠ: {paper.get('journal', 'N/A')}")
            print(f"  å‘è¡¨æ—¥æœŸ: {paper.get('publication_date', 'N/A')}")
        
        return True
    except Exception as e:
        print(f"PubMedçˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_arxiv_crawler():
    """æµ‹è¯•arXivçˆ¬è™«"""
    print("\næµ‹è¯•arXivçˆ¬è™«...")
    
    config = {
        'DATA_SOURCES': {
            'arxiv': {
                'base_url': 'http://export.arxiv.org/api/query',
                'categories': ['q-bio', 'cs.AI', 'cs.LG', 'stat.ML']
            }
        },
        'CRAWL_DELAY': 1,
        'MAX_PAPERS_PER_QUERY': 5
    }
    
    crawler = ArxivCrawler(config)
    
    try:
        # æµ‹è¯•æœç´¢
        papers = crawler.search_papers("machine learning", max_results=3)
        print(f"arXivæœç´¢ç»“æœ: {len(papers)} ç¯‡è®ºæ–‡")
        
        if papers:
            print("ç¬¬ä¸€ç¯‡è®ºæ–‡:")
            paper = papers[0]
            print(f"  æ ‡é¢˜: {paper.get('title', 'N/A')[:100]}...")
            print(f"  ä½œè€…: {', '.join(paper.get('authors', [])[:3])}")
            print(f"  åˆ†ç±»: {paper.get('journal', 'N/A')}")
            print(f"  å‘è¡¨æ—¥æœŸ: {paper.get('publication_date', 'N/A')}")
        
        return True
    except Exception as e:
        print(f"arXivçˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("MedLitAgent çˆ¬è™«åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•PubMedçˆ¬è™«
    pubmed_success = test_pubmed_crawler()
    
    # æµ‹è¯•arXivçˆ¬è™«
    arxiv_success = test_arxiv_crawler()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœ:")
    print(f"PubMedçˆ¬è™«: {'âœ“ æˆåŠŸ' if pubmed_success else 'âœ— å¤±è´¥'}")
    print(f"arXivçˆ¬è™«: {'âœ“ æˆåŠŸ' if arxiv_success else 'âœ— å¤±è´¥'}")
    
    if pubmed_success and arxiv_success:
        print("\nğŸ‰ æ‰€æœ‰çˆ¬è™«æµ‹è¯•é€šè¿‡ï¼")
        print("æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹çˆ¬å–æ–‡çŒ®:")
        print("  python main.py crawl 'machine learning' --sources pubmed arxiv --max-results 50")
    else:
        print("\nâš ï¸  éƒ¨åˆ†çˆ¬è™«æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé…ç½®ã€‚")

if __name__ == '__main__':
    main()