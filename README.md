# MedLitAgent - åŒ»å­¦æ–‡çŒ®çˆ¬å–å’Œæ•´ç†ç³»ç»Ÿ

MedLitAgentæ˜¯ä¸€ä¸ªæ™ºèƒ½çš„åŒ»å­¦æ–‡çŒ®çˆ¬å–å’Œæ•´ç†ç³»ç»Ÿï¼Œèƒ½å¤Ÿä»PubMedã€arXivç­‰ä¸»è¦åŒ»å­¦æ–‡çŒ®æ•°æ®åº“ä¸­è‡ªåŠ¨çˆ¬å–æ–‡çŒ®ï¼Œå¹¶ä½¿ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å¯¹æ–‡çŒ®è¿›è¡Œå…³é”®è¯æå–å’Œåˆ†ç±»æ•´ç†ã€‚

## ğŸŒŸ ä¸»è¦åŠŸèƒ½

- **å¤šæ•°æ®æºçˆ¬å–**: æ”¯æŒPubMedã€arXivç­‰ä¸»è¦åŒ»å­¦æ–‡çŒ®æ•°æ®åº“
- **æ™ºèƒ½å…³é”®è¯æå–**: ä½¿ç”¨NLPæŠ€æœ¯è‡ªåŠ¨æå–åŒ»å­¦å…³é”®è¯
- **è‡ªåŠ¨åˆ†ç±»**: åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»å­¦é¢†åŸŸè‡ªåŠ¨åˆ†ç±»
- **æ–‡çŒ®ç®¡ç†**: å®Œæ•´çš„æ–‡çŒ®æœç´¢ã€å­˜å‚¨å’Œç®¡ç†åŠŸèƒ½
- **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVã€Excelã€JSONã€PDFç­‰å¤šç§æ ¼å¼å¯¼å‡º
- **Webç•Œé¢**: ç”¨æˆ·å‹å¥½çš„Webç•Œé¢å’ŒRESTful API

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- **Python 3.12.9** (æ¨èç‰ˆæœ¬)
- pip (æœ€æ–°ç‰ˆæœ¬)
- Git

### 2. å®‰è£…ä¾èµ–

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ pip (æ¨è)
```bash
cd MedLitAgent

# ç¡®ä¿ä½¿ç”¨ Python 3.12.9
python --version  # åº”è¯¥æ˜¾ç¤º Python 3.12.9

# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æˆ–è€…ä½¿ç”¨ pyproject.toml
pip install -e .
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨ Docker
```bash
cd MedLitAgent

# æ„å»ºé•œåƒ
docker build -t medlitagent .

# è¿è¡Œå®¹å™¨
docker run -p 12000:12000 medlitagent

# æˆ–è€…ä½¿ç”¨ docker-compose
docker-compose up
```

#### æ–¹æ³•ä¸‰ï¼šPython ç‰ˆæœ¬ç®¡ç†
å¦‚æœæ‚¨éœ€è¦å®‰è£… Python 3.12.9ï¼š

**ä½¿ç”¨ pyenv (Linux/macOS):**
```bash
# å®‰è£… pyenv
curl https://pyenv.run | bash

# å®‰è£… Python 3.12.9
pyenv install 3.12.9
pyenv local 3.12.9

# éªŒè¯ç‰ˆæœ¬
python --version
```

**ä½¿ç”¨ conda:**
```bash
# åˆ›å»ºæ–°ç¯å¢ƒ
conda create -n medlitagent python=3.12.9
conda activate medlitagent

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒ

å¤åˆ¶ç¯å¢ƒé…ç½®æ–‡ä»¶å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œé…ç½®PubMed APIå¯†é’¥ç­‰ä¿¡æ¯ã€‚

### 4. è¿è¡Œç³»ç»Ÿ

#### å‘½ä»¤è¡Œæ¨¡å¼

```bash
# çˆ¬å–æ–‡çŒ®
python main.py crawl "machine learning" "deep learning" --sources pubmed arxiv --max-results 100

# æœç´¢æ–‡çŒ®
python main.py search --query "cancer" --category oncology --limit 10

# å¯¼å‡ºæ–‡çŒ®
python main.py export --format excel --category cardiology --output cardiology_papers.xlsx

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python main.py stats
```

#### Webç•Œé¢æ¨¡å¼

```bash
python main.py web
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://localhost:12000`

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### å‘½ä»¤è¡Œä½¿ç”¨

#### çˆ¬å–æ–‡çŒ®

```bash
python main.py crawl [å…³é”®è¯...] [é€‰é¡¹]
```

é€‰é¡¹ï¼š
- `--sources`: æ•°æ®æºé€‰æ‹© (pubmed, arxiv)
- `--max-results`: æ¯ä¸ªå…³é”®è¯æœ€å¤§çˆ¬å–æ•°é‡
- `--output`: è¾“å‡ºæ–‡ä»¶è·¯å¾„

ç¤ºä¾‹ï¼š
```bash
# ä»PubMedå’ŒarXivçˆ¬å–æœºå™¨å­¦ä¹ ç›¸å…³è®ºæ–‡
python main.py crawl "machine learning" "artificial intelligence" --sources pubmed arxiv --max-results 200

# çˆ¬å–å¿ƒè„ç—…å­¦è®ºæ–‡å¹¶å¯¼å‡ºä¸ºExcel
python main.py crawl "cardiology" "heart disease" --output cardiology.xlsx
```

#### æœç´¢æ–‡çŒ®

```bash
python main.py search [é€‰é¡¹]
```

é€‰é¡¹ï¼š
- `--query`: æœç´¢æŸ¥è¯¢è¯
- `--category`: åˆ†ç±»è¿‡æ»¤
- `--source`: æ•°æ®æºè¿‡æ»¤
- `--limit`: ç»“æœæ•°é‡é™åˆ¶

ç¤ºä¾‹ï¼š
```bash
# æœç´¢åŒ…å«"cancer"çš„è®ºæ–‡
python main.py search --query "cancer" --limit 20

# æœç´¢è‚¿ç˜¤å­¦åˆ†ç±»çš„è®ºæ–‡
python main.py search --category oncology --limit 50
```

#### å¯¼å‡ºæ–‡çŒ®

```bash
python main.py export [é€‰é¡¹]
```

é€‰é¡¹ï¼š
- `--format`: å¯¼å‡ºæ ¼å¼ (csv, excel, json, pdf, report)
- `--query`: æœç´¢æŸ¥è¯¢è¯
- `--category`: åˆ†ç±»è¿‡æ»¤
- `--source`: æ•°æ®æºè¿‡æ»¤
- `--limit`: ç»“æœæ•°é‡é™åˆ¶
- `--output`: è¾“å‡ºæ–‡ä»¶å

ç¤ºä¾‹ï¼š
```bash
# å¯¼å‡ºæ‰€æœ‰å¿ƒè„ç—…å­¦è®ºæ–‡ä¸ºExcelæ ¼å¼
python main.py export --format excel --category cardiology --output cardiology_papers.xlsx

# ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
python main.py export --format report --output summary_report.html
```

### Webç•Œé¢ä½¿ç”¨

å¯åŠ¨WebæœåŠ¡åï¼Œå¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **é¦–é¡µ**: ç³»ç»Ÿæ¦‚è§ˆå’Œå¿«é€Ÿå¼€å§‹
2. **çˆ¬å–æ–‡çŒ®**: é…ç½®å’Œå¯åŠ¨çˆ¬å–ä»»åŠ¡
3. **æœç´¢æ–‡çŒ®**: æœç´¢å’Œæµè§ˆå·²çˆ¬å–çš„æ–‡çŒ®
4. **ä»ªè¡¨æ¿**: æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯å’Œæ•°æ®åˆ†æ

### APIä½¿ç”¨

ç³»ç»Ÿæä¾›RESTful APIæ¥å£ï¼š

```bash
# å¥åº·æ£€æŸ¥
GET /api/health

# è·å–ç»Ÿè®¡ä¿¡æ¯
GET /api/statistics

# å¼€å§‹çˆ¬å–ä»»åŠ¡
POST /api/crawl
{
    "keywords": ["machine learning", "deep learning"],
    "sources": ["pubmed", "arxiv"],
    "max_results": 100
}

# æœç´¢è®ºæ–‡
GET /api/papers?query=cancer&category=oncology&page=1&per_page=20

# è·å–è®ºæ–‡è¯¦æƒ…
GET /api/papers/{paper_id}

# æå–å…³é”®è¯
POST /api/extract-keywords
{
    "text": "è®ºæ–‡æ–‡æœ¬å†…å®¹..."
}

# åˆ†ç±»æ–‡æœ¬
POST /api/classify-text
{
    "text": "è®ºæ–‡æ–‡æœ¬å†…å®¹..."
}
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
MedLitAgent/
â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.py          # ä¸»é…ç½®
â”‚   â””â”€â”€ medical_keywords.json # åŒ»å­¦å…³é”®è¯è¯å…¸
â”œâ”€â”€ src/                   # æºä»£ç 
â”‚   â”œâ”€â”€ crawlers/          # çˆ¬è™«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ base_crawler.py
â”‚   â”‚   â”œâ”€â”€ pubmed_crawler.py
â”‚   â”‚   â”œâ”€â”€ arxiv_crawler.py
â”‚   â”‚   â””â”€â”€ crawler_manager.py
â”‚   â”œâ”€â”€ nlp/               # è‡ªç„¶è¯­è¨€å¤„ç†
â”‚   â”‚   â”œâ”€â”€ keyword_extractor.py
â”‚   â”‚   â””â”€â”€ text_classifier.py
â”‚   â”œâ”€â”€ database/          # æ•°æ®åº“ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ database_manager.py
â”‚   â”œâ”€â”€ api/               # Web API
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ utils/             # å·¥å…·æ¨¡å—
â”‚       â””â”€â”€ export_utils.py
â”œâ”€â”€ templates/             # Webæ¨¡æ¿
â”œâ”€â”€ static/                # é™æ€æ–‡ä»¶
â”œâ”€â”€ data/                  # æ•°æ®ç›®å½•
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â””â”€â”€ main.py               # ä¸»ç¨‹åºå…¥å£
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹å˜é‡ï¼š

```bash
# æ•°æ®åº“é…ç½®
DATABASE_URL=sqlite:///medlit.db

# PubMed APIé…ç½®
PUBMED_API_KEY=your_api_key_here
PUBMED_EMAIL=your-email@example.com

# çˆ¬è™«é…ç½®
CRAWL_DELAY=1
MAX_PAPERS_PER_QUERY=1000

# Flaské…ç½®
FLASK_SECRET_KEY=your_secret_key_here
FLASK_DEBUG=True
```

### åŒ»å­¦åˆ†ç±»é…ç½®

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹åŒ»å­¦åˆ†ç±»ï¼š

- å¿ƒè„ç—…å­¦ (cardiology)
- è‚¿ç˜¤å­¦ (oncology)
- ç¥ç»å­¦ (neurology)
- å…ç–«å­¦ (immunology)
- è¯ç†å­¦ (pharmacology)
- é—ä¼ å­¦ (genetics)
- ä¼ æŸ“ç—…å­¦ (infectious_diseases)
- å¤–ç§‘å­¦ (surgery)
- å„¿ç§‘å­¦ (pediatrics)
- ç²¾ç¥ç—…å­¦ (psychiatry)
- æ”¾å°„å­¦ (radiology)
- ç—…ç†å­¦ (pathology)
- æµè¡Œç—…å­¦ (epidemiology)
- å…¬å…±å«ç”Ÿ (public_health)
- ä¸´åºŠè¯•éªŒ (clinical_trials)

## ğŸ“Š æ•°æ®æ ¼å¼

### è®ºæ–‡æ•°æ®ç»“æ„

```json
{
    "id": "è®ºæ–‡ID",
    "external_id": "å¤–éƒ¨æ•°æ®åº“ID",
    "title": "è®ºæ–‡æ ‡é¢˜",
    "abstract": "æ‘˜è¦",
    "authors": ["ä½œè€…1", "ä½œè€…2"],
    "journal": "æœŸåˆŠåç§°",
    "publication_date": "2023-01-01",
    "doi": "DOI",
    "url": "è®ºæ–‡URL",
    "source": "æ•°æ®æº",
    "predicted_category": "é¢„æµ‹åˆ†ç±»",
    "classification_confidence": 0.95,
    "extracted_keywords": [
        {
            "keyword": "å…³é”®è¯",
            "category": "åˆ†ç±»",
            "score": 2.5,
            "methods": ["dictionary", "tfidf"]
        }
    ]
}
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ†˜ æ”¯æŒ

å¦‚æœæ‚¨é‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ [Issues](https://github.com/your-username/MedLitAgent/issues)
2. åˆ›å»ºæ–°çš„ Issue
3. è”ç³»å¼€å‘å›¢é˜Ÿ

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š

- [PubMed API](https://www.ncbi.nlm.nih.gov/books/NBK25501/)
- [arXiv API](https://arxiv.org/help/api)
- [Flask](https://flask.palletsprojects.com/)
- [scikit-learn](https://scikit-learn.org/)
- [NLTK](https://www.nltk.org/)
- [spaCy](https://spacy.io/)
